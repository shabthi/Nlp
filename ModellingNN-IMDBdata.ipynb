{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Load the imdb dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "imdb, info = tfds.load(\"imdb_reviews\", with_info=True, as_supervised = True)\n",
    "import numpy as np\n",
    "train_data , test_data = imdb['train'],imdb['test']\n",
    "training_sentences=[]\n",
    "training_labels = []\n",
    "testing_sentences=[]\n",
    "testing_labels = []"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Get data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s,l in train_data:\n",
    "    training_sentences.append(str(s.numpy()))\n",
    "    training_labels.append(l.numpy())\n",
    "for s,l in test_data:\n",
    "    testing_sentences.append(str(s.numpy()))\n",
    "    testing_labels.append(l.numpy())\n",
    "training_labels_final = np.array(training_labels)\n",
    "testing_labels_final = np.array(testing_labels)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "embedding_dim = 16\n",
    "max_length = 120\n",
    "trunc_type = \"post\"\n",
    "oov_tok = \"<OOV>\"\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer = Tokenizer(num_words = vocab_size, oov_token = oov_tok)\n",
    "tokenizer.fit_on_texts(training_sentences)\n",
    "word_index = tokenizer.word_index\n",
    "sequences = tokenizer.texts_to_sequences(training_sentences)\n",
    "padded = pad_sequences(sequences, maxlen= max_length, truncating = trunc_type)\n",
    "\n",
    "testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
    "testing_padded = pad_sequences(testing_sequences, maxlen= max_length, truncating = trunc_type)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Modelling the NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 120, 16)           160000    \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 6)                 11526     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 171,533\n",
      "Trainable params: 171,533\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length = max_length),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(6, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(1,activation = 'sigmoid')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/5\n",
      "25000/25000 [==============================] - 10s 402us/sample - loss: 0.2405 - accuracy: 0.6158 - val_loss: 0.2416 - val_accuracy: 0.5977\n",
      "Epoch 2/5\n",
      "25000/25000 [==============================] - 7s 283us/sample - loss: 0.2383 - accuracy: 0.6229 - val_loss: 0.2394 - val_accuracy: 0.6088\n",
      "Epoch 3/5\n",
      "25000/25000 [==============================] - 7s 287us/sample - loss: 0.2356 - accuracy: 0.6302 - val_loss: 0.2369 - val_accuracy: 0.6163\n",
      "Epoch 4/5\n",
      "25000/25000 [==============================] - 7s 278us/sample - loss: 0.2326 - accuracy: 0.6386 - val_loss: 0.2341 - val_accuracy: 0.6228\n",
      "Epoch 5/5\n",
      "25000/25000 [==============================] - 7s 261us/sample - loss: 0.2291 - accuracy: 0.6478 - val_loss: 0.2310 - val_accuracy: 0.6364\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f05bdd8a9e8>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss = \"mean_squared_error\",optimizer = \"sgd\", metrics = ['accuracy'])\n",
    "model.fit(padded,training_labels_final,epochs = 5,validation_data=(testing_padded, testing_labels_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<OOV> photographs the <OOV> rocky mountains in a superb fashion and jimmy stewart and walter brennan give enjoyable performances as they always seem to do br br but come on hollywood a <OOV> telling the people of dawson city <OOV> to <OOV> themselves a <OOV> yes a <OOV> and to <OOV> the law themselves then <OOV> battling it out on the streets for control of the town br br nothing even remotely resembling that happened on the canadian side of the border during the <OOV> gold rush mr mann and company appear to have mistaken dawson city for <OOV> the canadian north for the american wild west br br canadian viewers be prepared for a <OOV> madness type of enjoyable\n",
      "[   1 6175    2    1 4916 4029    9    4  912 1622    3 1969 1307    3\n",
      " 2384 8836  201  746  361   15   34  208  308    6   83    8    8   19\n",
      "  214   22  352    4    1  990    2   82    5 3608  545    1    6    1\n",
      "  539    4    1  434    4    1    3    6    1    2 1176  539   95    1\n",
      " 8111   10   46   22    2 1996   16 1153    5    2  511    8    8  163\n",
      "   62 2624 7315   13  586   22    2 2297  507    5    2 3652  317    2\n",
      "    1 1835 3445  451 4030    3 1168  985    6   28 4091 3608  545   16\n",
      "    1    2 2297 2430   16    2  299 1357 1259    8    8 2297  803   29\n",
      " 2871   16    4    1 3028  564    5  746]\n",
      "b'Mann photographs the Alberta Rocky Mountains in a superb fashion, and Jimmy Stewart and Walter Brennan give enjoyable performances as they always seem to do. <br /><br />But come on Hollywood - a Mountie telling the people of Dawson City, Yukon to elect themselves a marshal (yes a marshal!) and to enforce the law themselves, then gunfighters battling it out on the streets for control of the town? <br /><br />Nothing even remotely resembling that happened on the Canadian side of the border during the Klondike gold rush. Mr. Mann and company appear to have mistaken Dawson City for Deadwood, the Canadian North for the American Wild West.<br /><br />Canadian viewers be prepared for a Reefer Madness type of enjoyable howl with this ludicrous plot, or, to shake your head in disgust.'\n"
     ]
    }
   ],
   "source": [
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "\n",
    "def decode_review(text):\n",
    "    return ' '.join([reverse_word_index.get(i, '?') for i in text])\n",
    "\n",
    "print(decode_review(padded[2]))\n",
    "print(padded[2])\n",
    "print(training_sentences[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(training_labels[0])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Using LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 120, 16)           160000    \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, 64)                12544     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 6)                 390       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 172,941\n",
      "Trainable params: 172,941\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length = max_length),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
    "    tf.keras.layers.Dense(6, activation = 'relu'),\n",
    "    tf.keras.layers.Dense(1,activation = 'sigmoid')\n",
    "])\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
